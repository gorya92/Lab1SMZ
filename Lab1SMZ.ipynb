{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca43cc5",
   "metadata": {},
   "source": [
    "Краткое описание действий функции:\n",
    "\n",
    "Проверяется, что размерности входного тензора и ядра корректны.\n",
    "Вычисляются размеры выходного тензора после свертки с учетом параметров stride и padding.\n",
    "Добавляется паддинг к входному тензору в соответствии с указанным padding.\n",
    "Инициализируется выходной тензор нулями.\n",
    "Происходит итерация по батчам, выходным каналам, высоте и ширине выходного тензора.\n",
    "Для каждого пикселя выходного тензора вычисляется свертка, умножая соответствующие элементы входного тензора и ядра и суммируя результат.\n",
    "Если указан параметр bias, добавляется соответствующее значение к выходу свертки для каждого выходного канала.\n",
    "Возвращается полученный выходной тензор.\n",
    "Таким образом, функция реализует базовую операцию свертки с учетом параметров, которые могут быть настроены пользователем, таких как шаг (stride) и заполнение (padding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a750172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convolution2D(input_tensor, weight, bias=None, stride=1, padding=0):\n",
    "    if len(input_tensor.shape) == 4 and len(weight.shape) == 4:\n",
    "        batch_size, in_channels, input_height, input_width = input_tensor.shape\n",
    "        out_channels, _, kernel_height, kernel_width = weight.shape\n",
    "    else:\n",
    "        raise ValueError(\"Неверные размеры входного тензора или ядра\")\n",
    "\n",
    "    # Проверяем, что число входных каналов совпадает\n",
    "    if in_channels != weight.shape[1]:\n",
    "        raise ValueError(\"Число входных каналов в тензоре и ядре должно совпадать\")\n",
    "\n",
    "    # Вычисляем размер выходного тензора после свертки\n",
    "    output_height = (input_height + 2 * padding - kernel_height) // stride + 1\n",
    "    output_width = (input_width + 2 * padding - kernel_width) // stride + 1\n",
    "\n",
    "    # Добавляем паддинг к входному тензору\n",
    "    padded_input = np.pad(input_tensor, ((0, 0), (0, 0), (padding, padding), (padding, padding)), mode='constant')\n",
    "\n",
    "    # Инициализируем выходной тензор\n",
    "    output_tensor = np.zeros((batch_size, out_channels, output_height, output_width))\n",
    "\n",
    "    # Проходим по батчам, каналам, высоте и ширине выходного тензора\n",
    "    for b in range(batch_size):\n",
    "        for o_c in range(out_channels):\n",
    "            for h_out in range(output_height):\n",
    "                for w_out in range(output_width):\n",
    "                    h_start = h_out * stride\n",
    "                    h_end = h_start + kernel_height\n",
    "                    w_start = w_out * stride\n",
    "                    w_end = w_start + kernel_width\n",
    "\n",
    "                    # Вычисляем свертку для каждого пикселя выходного тензора\n",
    "                    output_tensor[b, o_c, h_out, w_out] = np.sum(\n",
    "                        padded_input[b, :, h_start:h_end, w_start:w_end] * weight[o_c, :, :, :]\n",
    "                    )\n",
    "\n",
    "    # Добавляем bias, если он предоставлен\n",
    "    if bias is not None:\n",
    "        output_tensor += bias.reshape((1, -1, 1, 1))\n",
    "\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "371bce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor:\n",
      "[[[[0.23314882 0.39148445 0.71442231 0.9008591 ]\n",
      "   [0.35922559 0.99981858 0.76363684 0.13631999]\n",
      "   [0.11733673 0.94417158 0.69435637 0.36697482]\n",
      "   [0.79169101 0.79016508 0.04840143 0.01889929]]\n",
      "\n",
      "  [[0.8278443  0.25121743 0.98348976 0.86727951]\n",
      "   [0.72823026 0.48172071 0.08334341 0.38364972]\n",
      "   [0.86873102 0.52054249 0.89497642 0.71645055]\n",
      "   [0.46724311 0.80585002 0.40315365 0.3392572 ]]\n",
      "\n",
      "  [[0.06145446 0.34545074 0.742483   0.62089049]\n",
      "   [0.21858446 0.20237001 0.01834002 0.10209789]\n",
      "   [0.77133211 0.63824574 0.15708099 0.51388021]\n",
      "   [0.93219716 0.86446862 0.96755992 0.80381241]]]\n",
      "\n",
      "\n",
      " [[[0.77198704 0.98402373 0.39424857 0.33101982]\n",
      "   [0.64195836 0.2930071  0.01149996 0.28734553]\n",
      "   [0.48284387 0.27306899 0.26791118 0.78881806]\n",
      "   [0.23779086 0.58277097 0.93527114 0.00804132]]\n",
      "\n",
      "  [[0.95951784 0.50398577 0.70067087 0.64124223]\n",
      "   [0.47850008 0.54615476 0.37215577 0.78314499]\n",
      "   [0.24549923 0.18072547 0.70371832 0.3741829 ]\n",
      "   [0.04686203 0.29613731 0.11507961 0.2118812 ]]\n",
      "\n",
      "  [[0.26738328 0.91823397 0.75183692 0.19609163]\n",
      "   [0.10123259 0.85963756 0.97681472 0.59978355]\n",
      "   [0.9705878  0.94198986 0.85582512 0.65067141]\n",
      "   [0.11883983 0.7936108  0.06602837 0.14113612]]]]\n",
      "\n",
      "Weight (Kernel):\n",
      "[[[[0.36266543 0.94135342 0.24269737]\n",
      "   [0.74091737 0.16914834 0.73273499]\n",
      "   [0.76292273 0.69587951 0.07165881]]\n",
      "\n",
      "  [[0.93437297 0.96976958 0.91844942]\n",
      "   [0.84620492 0.67792644 0.10308524]\n",
      "   [0.64546866 0.10086315 0.1688652 ]]\n",
      "\n",
      "  [[0.70979313 0.14238444 0.80892735]\n",
      "   [0.03450771 0.39883944 0.38576343]\n",
      "   [0.95520681 0.97915479 0.81483168]]]\n",
      "\n",
      "\n",
      " [[[0.84413923 0.71757771 0.11350081]\n",
      "   [0.72780213 0.54170761 0.11998167]\n",
      "   [0.38726124 0.76927509 0.1903664 ]]\n",
      "\n",
      "  [[0.86742252 0.09567717 0.73088653]\n",
      "   [0.50925518 0.65856059 0.68342641]\n",
      "   [0.15489827 0.79568099 0.12517886]]\n",
      "\n",
      "  [[0.09496103 0.94963886 0.58483618]\n",
      "   [0.73222921 0.40760352 0.9584784 ]\n",
      "   [0.93838697 0.70808845 0.1110168 ]]]\n",
      "\n",
      "\n",
      " [[[0.87086644 0.49300751 0.63512272]\n",
      "   [0.61679906 0.39626644 0.58122765]\n",
      "   [0.9568132  0.79530547 0.3426738 ]]\n",
      "\n",
      "  [[0.38786482 0.090253   0.09861569]\n",
      "   [0.25815787 0.62308453 0.16196691]\n",
      "   [0.87018322 0.97428359 0.65192697]]\n",
      "\n",
      "  [[0.89988395 0.93798843 0.73592673]\n",
      "   [0.00173828 0.39691992 0.3455721 ]\n",
      "   [0.69735088 0.43102977 0.12239537]]]\n",
      "\n",
      "\n",
      " [[[0.79520745 0.79710083 0.87661874]\n",
      "   [0.83236887 0.67138582 0.51824734]\n",
      "   [0.61968134 0.73527719 0.24935437]]\n",
      "\n",
      "  [[0.31968377 0.60897926 0.14664202]\n",
      "   [0.72874584 0.73244876 0.71390026]\n",
      "   [0.92071187 0.69158535 0.34452194]]\n",
      "\n",
      "  [[0.65113648 0.90158766 0.18837172]\n",
      "   [0.12365635 0.13162795 0.52783775]\n",
      "   [0.18585877 0.84208125 0.3604358 ]]]]\n",
      "\n",
      "Bias:\n",
      "[0.65193863 0.33721083 0.32486092 0.59518557]\n",
      "\n",
      "Output Tensor:\n",
      "[[[[ 2.5784633   4.79205914  5.22175308  3.91452597]\n",
      "   [ 5.39027739  8.98419146  9.00974678  7.18356556]\n",
      "   [ 6.8922611   9.74270569  9.05257089  5.62042971]\n",
      "   [ 4.7562228   7.14490465  6.96395173  3.9290886 ]]\n",
      "\n",
      "  [[ 2.86716965  4.87191275  5.04003782  4.02219084]\n",
      "   [ 4.12200232  7.78286118  7.92237852  5.93386782]\n",
      "   [ 5.47515301  8.74145478  8.44306026  5.08635522]\n",
      "   [ 4.68856346  7.43782979  6.55436665  4.04477155]]\n",
      "\n",
      "  [[ 3.11590886  4.76219631  5.22372352  3.50669284]\n",
      "   [ 4.52493505  7.97135327  8.55505352  6.6916621 ]\n",
      "   [ 5.74035385  8.20056293  7.5196681   4.45559834]\n",
      "   [ 4.16869877  5.41079886  4.87074147  2.81917131]]\n",
      "\n",
      "  [[ 3.37077646  5.75489078  5.79656681  4.3250533 ]\n",
      "   [ 5.53930381  8.29020609  9.23458081  7.33331232]\n",
      "   [ 6.99820996  9.68085592  8.83920508  5.27015559]\n",
      "   [ 5.37497843  7.05590518  6.17494947  3.54857176]]]\n",
      "\n",
      "\n",
      " [[[ 4.07464172  6.42620172  6.10578053  4.18009296]\n",
      "   [ 6.99645496 10.40170698  8.96253204  6.82040931]\n",
      "   [ 5.24511315  6.88664413  8.05501743  5.2987249 ]\n",
      "   [ 3.36008038  5.2738831   4.76090479  4.20607693]]\n",
      "\n",
      "  [[ 4.00473607  5.91310797  5.85045804  4.46063458]\n",
      "   [ 5.62367097  9.70602974  8.95092151  6.04444185]\n",
      "   [ 4.29344391  8.05516493  7.89694222  4.44885187]\n",
      "   [ 3.58396136  4.57526386  4.67623747  3.46386354]]\n",
      "\n",
      "  [[ 3.88770737  5.32306534  5.14902936  3.62486347]\n",
      "   [ 4.91006621  8.40350345  7.96960141  5.70417989]\n",
      "   [ 3.67102818  6.29543862  7.47835227  4.6003028 ]\n",
      "   [ 3.21148819  5.09236749  4.48911361  3.43217724]]\n",
      "\n",
      "  [[ 4.66517739  6.87950213  5.99500699  4.03393724]\n",
      "   [ 6.74772762  9.03412208  8.63348617  6.0601413 ]\n",
      "   [ 4.22864773  6.9587422   7.19158329  5.30613249]\n",
      "   [ 3.58990418  4.92700163  5.51596576  4.0834189 ]]]]\n"
     ]
    }
   ],
   "source": [
    "# Пример использования\n",
    "input_tensor = np.random.rand(2, 3, 4, 4)  # Batch size: 2, Channels: 3, Height: 4, Width: 4\n",
    "weight = np.random.rand(4, 3, 3, 3)         # Output Channels: 4, Input Channels: 3, Kernel Height: 3, Kernel Width: 3\n",
    "bias = np.random.rand(4)                     # Bias for each output channel\n",
    "stride = 1\n",
    "padding = 1\n",
    "\n",
    "# Вызываем функцию convolution2D\n",
    "output_tensor = convolution2D(input_tensor, weight, bias, stride, padding)\n",
    "\n",
    "# Выводим результаты\n",
    "print(\"Input Tensor:\")\n",
    "print(input_tensor)\n",
    "print(\"\\nWeight (Kernel):\")\n",
    "print(weight)\n",
    "print(\"\\nBias:\")\n",
    "print(bias)\n",
    "print(\"\\nOutput Tensor:\")\n",
    "print(output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "541513a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "\n",
    "class TestConvolution2D(unittest.TestCase):\n",
    "\n",
    "    def test_result_shape(self):\n",
    "        # Тест проверяет, что форма выходного тензора правильная\n",
    "        input_tensor = np.random.rand(2, 3, 4, 4)\n",
    "        weight = np.random.rand(4, 3, 3, 3)\n",
    "        bias = np.random.rand(4)\n",
    "        output_tensor = convolution2D(input_tensor, weight, bias)\n",
    "        self.assertEqual(output_tensor.shape, (2, 4, 2, 2))  # Пример формы для этого теста\n",
    "\n",
    "    def test_no_bias(self):\n",
    "        # Тест проверяет, что результат без bias совпадает с результатом без bias из PyTorch\n",
    "        input_tensor = np.random.rand(2, 3, 4, 4)\n",
    "        weight = np.random.rand(4, 3, 3, 3)\n",
    "        output_tensor_custom = convolution2D(input_tensor, weight)\n",
    "        \n",
    "        import torch\n",
    "        import torch.nn.functional as F\n",
    "        input_tensor_torch = torch.tensor(input_tensor, dtype=torch.float32)\n",
    "        weight_torch = torch.tensor(weight, dtype=torch.float32)\n",
    "        output_tensor_torch = F.conv2d(input_tensor_torch, weight_torch).numpy()\n",
    "\n",
    "        np.testing.assert_allclose(output_tensor_custom, output_tensor_torch, rtol=1e-5, atol=1e-8)\n",
    "\n",
    "    def test_padding(self):\n",
    "        # Тест проверяет, что результат с 'same' padding совпадает с результатом из PyTorch\n",
    "        input_tensor = np.random.rand(2, 3, 4, 4)\n",
    "        weight = np.random.rand(4, 3, 3, 3)\n",
    "        bias = np.random.rand(4)\n",
    "        output_tensor_custom = convolution2D(input_tensor, weight, bias, padding=1)\n",
    "        \n",
    "        import torch\n",
    "        import torch.nn.functional as F\n",
    "        input_tensor_torch = torch.tensor(input_tensor, dtype=torch.float32)\n",
    "        weight_torch = torch.tensor(weight, dtype=torch.float32)\n",
    "        bias_torch = torch.tensor(bias, dtype=torch.float32)\n",
    "        output_tensor_torch = F.conv2d(input_tensor_torch, weight_torch, bias=bias_torch, padding=1).numpy()\n",
    "\n",
    "        np.testing.assert_allclose(output_tensor_custom, output_tensor_torch, rtol=1e-5, atol=1e-8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d9a36eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 1.634s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1b393092bb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c72eb22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
